{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/objdetect/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from keras.applications import  VGG16\n",
    "from keras.models import Sequential\n",
    "from keras import losses\n",
    "from keras_tqdm import TQDMNotebookCallback, TQDMCallback\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Reshape\n",
    "from keras_tqdm import TQDMCallback\n",
    "from keras.utils import np_utils\n",
    "from cat_dogs_dataset import GetDataGenerators,GetRawDataGenerators\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from TreatData import *\n",
    "\n",
    "np.random.seed(1675)  # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the transfer learning layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "All Layers:\n",
      "0 input_1 (None, 224, 224, 3)\n",
      "1 block1_conv1 (None, 224, 224, 64)\n",
      "2 block1_conv2 (None, 224, 224, 64)\n",
      "3 block1_pool (None, 112, 112, 64)\n",
      "4 block2_conv1 (None, 112, 112, 128)\n",
      "5 block2_conv2 (None, 112, 112, 128)\n",
      "6 block2_pool (None, 56, 56, 128)\n",
      "7 block3_conv1 (None, 56, 56, 256)\n",
      "8 block3_conv2 (None, 56, 56, 256)\n",
      "9 block3_conv3 (None, 56, 56, 256)\n",
      "10 block3_pool (None, 28, 28, 256)\n",
      "11 block4_conv1 (None, 28, 28, 512)\n",
      "12 block4_conv2 (None, 28, 28, 512)\n",
      "13 block4_conv3 (None, 28, 28, 512)\n",
      "14 block4_pool (None, 14, 14, 512)\n",
      "15 block5_conv1 (None, 14, 14, 512)\n",
      "16 block5_conv2 (None, 14, 14, 512)\n",
      "17 block5_conv3 (None, 14, 14, 512)\n",
      "18 block5_pool (None, 7, 7, 512)\n",
      "19 flatten (None, 25088)\n",
      "20 fc1 (None, 4096)\n",
      "21 fc2 (None, 4096)\n",
      "22 predictions (None, 1000)\n",
      "\n",
      "\n",
      "Frozen Layers:\n",
      "0 input_1 (None, 224, 224, 3)\n",
      "1 block1_conv1 (None, 224, 224, 64)\n",
      "2 block1_conv2 (None, 224, 224, 64)\n",
      "3 block1_pool (None, 112, 112, 64)\n",
      "4 block2_conv1 (None, 112, 112, 128)\n",
      "5 block2_conv2 (None, 112, 112, 128)\n",
      "6 block2_pool (None, 56, 56, 128)\n",
      "7 block3_conv1 (None, 56, 56, 256)\n",
      "8 block3_conv2 (None, 56, 56, 256)\n",
      "9 block3_conv3 (None, 56, 56, 256)\n",
      "10 block3_pool (None, 28, 28, 256)\n"
     ]
    }
   ],
   "source": [
    "LastLayer = 10  # Last transfer learning layer number. Check the summary to make the appropriate choice.\n",
    "\n",
    "batch_size=16\n",
    "steps = CalculateSteps(\"DatasetJPG\",batch_size)\n",
    "\n",
    "vgg16_model = VGG16(weights=\"vgg16_weights_tf_dim_ordering_tf_kernels.h5\", include_top=True)\n",
    "print('\\n')\n",
    "print('All Layers:')\n",
    "\n",
    "\n",
    "for i, layer in enumerate(vgg16_model.layers):\n",
    "    print(i , layer.name, layer.output_shape)\n",
    "    \n",
    "feature_layers = vgg16_model.layers[:(LastLayer+1)]\n",
    "bottleneckModel =  Sequential(feature_layers)\n",
    "print('\\n')\n",
    "print('Frozen Layers:')\n",
    "\n",
    "\n",
    "for i, layer in enumerate(bottleneckModel.layers):\n",
    "    print(i , layer.name, layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1303 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
    "# DatasetNorm\n",
    "generator = datagen.flow_from_directory(\"DatasetJPG\", \n",
    "                                        target_size=(224, 224), \n",
    "                                        batch_size=batch_size, \n",
    "                                        shuffle=True,\n",
    "                                        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape:(1296, 28, 28, 256)\n",
      "output shape:(81, 16)\n"
     ]
    }
   ],
   "source": [
    "totalfeatures = []\n",
    "totaltargets = []\n",
    "for i in range(steps):\n",
    "    X, y = generator.next()\n",
    "    features = bottleneckModel.predict(X)\n",
    "    totalfeatures.append(features)\n",
    "    totaltargets.append(y.reshape((-1,)))    \n",
    "    \n",
    "totalfeatures = np.vstack(totalfeatures)\n",
    "totaltargets = np.vstack(totaltargets)\n",
    "\n",
    "print(\"features shape:\" + str(totalfeatures.shape))\n",
    "print(\"output shape:\" + str(totaltargets.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00001\n",
    "epochs = 100\n",
    "IS_NOTEBOOK = True\n",
    "callbacks = [TQDMNotebookCallback()] if IS_NOTEBOOK else [TQDMCallback()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = 9\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "result = []\n",
    "history_list = []\n",
    "\n",
    "org_shape = totalfeatures.shape\n",
    "\n",
    "Xflat = totalfeatures.reshape((org_shape[0], -1))\n",
    "yflat = totaltargets.reshape(-1)\n",
    "\n",
    "X = totalfeatures\n",
    "y = keras.utils.to_categorical(yflat, num_classes=4)\n",
    "\n",
    "for train, test in kfold.split(X , yflat):\n",
    "    \n",
    "    fc_layers = [\n",
    "        Conv2D(512, kernel_size=(2, 2), activation='relu', padding='same', input_shape=org_shape[1:]),#, input_shape=bottleneck_features_train.data.shape[1:]),\n",
    "        Conv2D(512, kernel_size=(2, 2), activation='relu', padding='same'),\n",
    "        Conv2D(512, kernel_size=(2, 2), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "        \n",
    "        Conv2D(512, kernel_size=(2, 2), activation='relu', padding='same'),\n",
    "        Conv2D(512, kernel_size=(2, 2), activation='relu', padding='same'),\n",
    "        Conv2D(512, kernel_size=(2, 2), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "        Flatten(input_shape=org_shape[1:]),\n",
    "        Dense(512, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)),\n",
    "        #Dense(512, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01)),  ## adicionei para FL-10\n",
    "        Dense(4, activation=\"softmax\")]\n",
    "\n",
    "    model = Sequential(fc_layers)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss=losses.categorical_crossentropy,\n",
    "                          optimizer=keras.optimizers.Adam(lr=lr),\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X[train], y[train],\n",
    "                batch_size = batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=0,\n",
    "                validation_data=(X[test], y[test]),\n",
    "                callbacks=callbacks)\n",
    "    \n",
    "    score, acc = model.evaluate(X[test], y[test], verbose=0)\n",
    "    print(\"Test score: %.3f, accuracy: %.3f\" % (score,acc))\n",
    "    result.append((score, acc))\n",
    "    history_list.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvando Modelo... \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "=================================================================\n",
      "Total params: 1,735,488\n",
      "Trainable params: 1,735,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 200704)            0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               102760960 \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 102,893,316\n",
      "Trainable params: 102,893,316\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value dense_22/kernel\n\t [[Node: dense_22/kernel/_1148 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_8_dense_22/kernel\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_22/kernel)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/objdetect/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/objdetect/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/objdetect/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/objdetect/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value dense_22/kernel\n\t [[Node: dense_22/kernel/_1148 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_8_dense_22/kernel\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_22/kernel)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5dfdee01dc4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# serialize weights to HDF5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSaveModelName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved model to disk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/objdetect/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/objdetect/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36msave_weights_to_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2961\u001b[0m         \u001b[0msymbolic_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2962\u001b[0;31m         \u001b[0mweight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2963\u001b[0m         \u001b[0mweight_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2964\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/objdetect/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2325\u001b[0m     \"\"\"\n\u001b[1;32m   2326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2328\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/objdetect/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/objdetect/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/objdetect/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/objdetect/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value dense_22/kernel\n\t [[Node: dense_22/kernel/_1148 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_8_dense_22/kernel\", _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_22/kernel)]]"
     ]
    }
   ],
   "source": [
    "SaveModelName = \"modelSA_\" + str(LastLayer) + \".h5\"\n",
    "#SaveModelName = \"model_\" + str(LastLayer) + \".h5\"\n",
    "SaveModelName_Json = SaveModelName.replace(\".h5\",'.json')\n",
    "\n",
    "if os.path.isfile(SaveModelName) and os.path.isfile(SaveModelName_Json):\n",
    "    print('This model exists!')\n",
    "\n",
    "else:\n",
    "    print('Saving the model... ')\n",
    "    \n",
    "    bottleneckModel.summary()\n",
    "    model.summary()\n",
    "\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(SaveModelName_Json, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(SaveModelName)\n",
    "    print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import datetime\n",
    "from keras.applications import  VGG16\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from keras import losses\n",
    "from keras_tqdm import TQDMNotebookCallback, TQDMCallback\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Reshape\n",
    "from keras_tqdm import TQDMCallback\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from cat_dogs_dataset import GetDataGenerators,GetRawDataGenerators\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from TreatData import *\n",
    "\n",
    "\n",
    "np.random.seed(1675)  # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LOAD Frozen MODEL\n",
    "\n",
    "LastLayer = 18 # 10, 14 or 18 or 20 (out) ( FL-7, FL-10 or FL-13 )\n",
    "vgg16_model = VGG16(weights=\"vgg16_weights_tf_dim_ordering_tf_kernels.h5\", include_top=True)\n",
    "    \n",
    "feature_layers = vgg16_model.layers[:(LastLayer+1)]\n",
    "bottleneckModel =  Sequential(feature_layers)\n",
    "\n",
    "bottleneckModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# LOAD Trainable MODEL\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "LoadedModelName = \"modelSA_\" + str(LastLayer) + \".h5\"\n",
    "#LoadedModelName = \"model_\" + str(LastLayer) + \".h5\"\n",
    "LoadeModelName_Json = LoadedModelName.replace(\".h5\",'.json')\n",
    "\n",
    "# load json and create model\n",
    "json_file = open(LoadeModelName_Json, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(LoadedModelName)\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "#loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1303 images belonging to 4 classes.\n",
      "(1303, 224, 224, 3)\n",
      "(1303,)\n"
     ]
    }
   ],
   "source": [
    "# Copy down the number of files\n",
    "num_files = 1303 #\n",
    "\n",
    "generator = datagen.flow_from_directory(Dataset, \n",
    "                                        target_size=(224, 224), \n",
    "                                        batch_size=num_files,\n",
    "                                        class_mode='sparse')\n",
    "X, y = generator.next()\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_10 (Flatten)         (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 12,977,924\n",
      "Trainable params: 12,977,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "bottleneckModel.summary()\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Predictions\n",
    "\n",
    "features4 = bottleneckModel.predict(X)\n",
    "y_pred_before_softmax = loaded_model.predict(features4)\n",
    "\n",
    "\n",
    "y_pred = np.argmax(y_pred_before_softmax,axis=-1)\n",
    "Class1_ind = np.where(y_pred==0)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#y_pred[Class1_ind] = np.random.randint(2, size=945)\n",
    "\n",
    "\n",
    "value = int((y_pred[Class1_ind].shape[0])*0.1)\n",
    "value2 = int((y_pred[Class1_ind].shape[0])*0.)\n",
    "a = np.random.randint(2, size=y_pred[Class1_ind].shape[0]-value)\n",
    "b = np.random.randint(1, size=y_pred[Class1_ind].shape[0]+(1-value))\n",
    "\n",
    "y_pred[Class1_ind] = np.concatenate((a, b), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "#class_names = iris.target_names\n",
    "class_names = ['AGR', 'FOR', 'HRB', 'SHR']\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    #else:\n",
    "        #print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cnf_matrix = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(cnf_matrix)\n",
    "print('\\n')\n",
    "print(norm_cnf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Layer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import losses\n",
    "from keras.optimizers import RMSprop\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from random import randint\n",
    "import matplotlib.pylab as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7fe34aaf2438>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottleneckModel\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1303 images belonging to 4 classes.\n",
      "Found 1303 images belonging to 4 classes.\n",
      "(1303, 224, 224, 3)\n",
      "(1303,)\n"
     ]
    }
   ],
   "source": [
    "Dataset = \"DatasetJPG\" #\"Dataset_C\"\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "datagen.flow_from_directory(Dataset,Dataset)\n",
    "\n",
    "num_files = 1303 # 5008\n",
    "\n",
    "generator = datagen.flow_from_directory(Dataset, \n",
    "                                        target_size=(224, 224), \n",
    "                                        batch_size=num_files,\n",
    "                                        class_mode='sparse')\n",
    "X, y = generator.next()\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class1_indexes = np.where(y==0)\n",
    "Class2_indexes = np.where(y==1)\n",
    "Class3_indexes = np.where(y==2)\n",
    "Class4_indexes = np.where(y==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_index = 0   # 0, 1, 2 or 3\n",
    "img_index = 46 # 0 to max_img_index\n",
    "\n",
    "Classes_Vet = [Class1_indexes, Class2_indexes, Class3_indexes, Class4_indexes]\n",
    "max_img_index = np.array(Classes_Vet[class_index]).size\n",
    "\n",
    "img_array = X[Classes_Vet[class_index]][img_index]\n",
    "\n",
    "plt.imshow(img_array)\n",
    "img_array=img_array.reshape((1,224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LastLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Calculate all the features of each layer of each class for all images. Warning: it uses a lot of disk space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer:  1\n",
      "Progress:  1.92 %\n",
      "Progress:  3.84 %\n",
      "Progress:  5.76 %\n",
      "Progress:  7.69 %\n",
      "Inference Time [s]:  127.41\n",
      "Layer:  2\n",
      "Progress:  9.61 %\n",
      "Progress:  11.53 %\n",
      "Progress:  13.46 %\n",
      "Progress:  15.38 %\n",
      "Inference Time [s]:  674.64\n",
      "Layer:  4\n",
      "Progress:  17.3 %\n",
      "Progress:  19.23 %\n",
      "Progress:  21.15 %\n",
      "Progress:  23.07 %\n",
      "Inference Time [s]:  28.13\n",
      "Layer:  5\n",
      "Progress:  25.0 %\n",
      "Progress:  26.92 %\n",
      "Progress:  28.84 %\n",
      "Progress:  30.76 %\n",
      "Inference Time [s]:  35.96\n",
      "Layer:  7\n",
      "Progress:  32.69 %\n",
      "Progress:  34.61 %\n",
      "Progress:  36.53 %\n",
      "Progress:  38.46 %\n",
      "Inference Time [s]:  13.71\n",
      "Layer:  8\n",
      "Progress:  40.38 %\n",
      "Progress:  42.3 %\n",
      "Progress:  44.23 %\n",
      "Progress:  46.15 %\n",
      "Inference Time [s]:  21.26\n",
      "Layer:  9\n",
      "Progress:  48.07 %\n",
      "Progress:  50.0 %\n",
      "Progress:  51.92 %\n",
      "Progress:  53.84 %\n",
      "Inference Time [s]:  18.78\n",
      "Layer:  11\n",
      "Progress:  55.76 %\n",
      "Progress:  57.69 %\n",
      "Progress:  59.61 %\n",
      "Progress:  61.53 %\n",
      "Inference Time [s]:  9.73\n",
      "Layer:  12\n",
      "Progress:  63.46 %\n",
      "Progress:  65.38 %\n",
      "Progress:  67.3 %\n",
      "Progress:  69.23 %\n",
      "Inference Time [s]:  11.72\n",
      "Layer:  13\n",
      "Progress:  71.15 %\n",
      "Progress:  73.07 %\n",
      "Progress:  75.0 %\n",
      "Progress:  76.92 %\n",
      "Inference Time [s]:  10.67\n",
      "Layer:  15\n",
      "Progress:  78.84 %\n",
      "Progress:  80.76 %\n",
      "Progress:  82.69 %\n",
      "Progress:  84.61 %\n",
      "Inference Time [s]:  6.29\n",
      "Layer:  16\n",
      "Progress:  86.53 %\n",
      "Progress:  88.46 %\n",
      "Progress:  90.38 %\n",
      "Progress:  92.3 %\n",
      "Inference Time [s]:  5.81\n",
      "Layer:  17\n",
      "Progress:  94.23 %\n",
      "Progress:  96.15 %\n",
      "Progress:  98.07 %\n",
      "Progress:  100.0 %\n",
      "Inference Time [s]:  5.38\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import math\n",
    "\n",
    "Mean_Layer = []\n",
    "cont = 0\n",
    "\n",
    "for layer_id in [1, 2, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17]:\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    print('Layer: ', layer_id)\n",
    "    MeanVetClass = []\n",
    "    \n",
    "    for class_index in [0, 1, 2, 3]:\n",
    "        max_img_index = np.array(Classes_Vet[class_index]).size\n",
    "        \n",
    "        layer_output_Vet = []\n",
    "        #print('Number of Images: ', max_img_index)\n",
    "\n",
    "        img_array = X[Classes_Vet[class_index]]\n",
    "        #print(\"Layer Number:\", layer_id)\n",
    "\n",
    "        if(layer_id <= LastLayer ): # Base CNN model \n",
    "            LayerName = bottleneckModel.layers[layer_id].name\n",
    "            #print(\"BottleNeck Network Layer:\")\n",
    "            #print(LayerName)\n",
    "\n",
    "            model1=Model(inputs=bottleneckModel.input,outputs=bottleneckModel.get_layer(LayerName).get_output_at(0))\n",
    "            H=model1.predict(img_array);\n",
    "\n",
    "\n",
    "        else: # Complete model (Base CNN model + CNN model)\n",
    "            LayerName = bottleneckModel.layers[LastLayer].name\n",
    "            LayerName_trainable = loaded_model.layers[layer_id-LastLayer-1].name\n",
    "            #print(\"BottleNeck Network Layer:\", LayerName )\n",
    "            #print(\"Trainable Network Layer:\", LayerName_trainable)\n",
    "\n",
    "            model1=Model(inputs=bottleneckModel.input,outputs=bottleneckModel.get_layer(LayerName).get_output_at(0))\n",
    "            H=model1.predict(img_array);\n",
    "\n",
    "            model2=Model(inputs=loaded_model.input,outputs=loaded_model.get_layer(LayerName_trainable).get_output_at(0))\n",
    "            H = model2.predict(H);\n",
    "\n",
    "\n",
    "        # Remove first dimension\n",
    "        H_np = np.array(H,dtype=np.double)\n",
    "        total_num_pixels = H_np.shape[1]*H_np.shape[2]*H_np.shape[3]\n",
    "        layer_output_reshape = H_np.reshape(H_np.shape[0],total_num_pixels)\n",
    "\n",
    "        SaveStrName = 'Layer_' + str(layer_id) + '_' + 'Class_' + str(class_index) + '.npy'\n",
    "\n",
    "        np.save(SaveStrName, layer_output_reshape)\n",
    "\n",
    "\n",
    "\n",
    "        #print(\"Calculating the Class Mean Vector for Class: \", class_index)\n",
    "        cont+=1\n",
    "        print(\"Progress: \", str(math.trunc((cont/(13*4))*10000)/100) + ' %')\n",
    "        \n",
    "    stop = timeit.default_timer()\n",
    "    print('Inference Time [s]: ', math.trunc((stop - start)*100)/100)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Calculate the mean and standard deviation of all the features of each layer of each class for all images. Warning: it uses a lot of RAM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer_1_Class_0.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (47, 3211264)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (3211264,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (1, 3211264)\n",
      "\n",
      "\n",
      "Layer_1_Class_1.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (962, 3211264)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (3211264,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (2, 3211264)\n",
      "\n",
      "\n",
      "Layer_1_Class_2.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (183, 3211264)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (3211264,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (3, 3211264)\n",
      "\n",
      "\n",
      "Layer_1_Class_3.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (111, 3211264)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (3211264,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (4, 3211264)\n",
      "\n",
      "\n",
      "Std between the Mean of all Classes individually for that Layer: \n",
      " (3211264,)\n",
      "Appending the Mean of the previoius Std for each Layer: \n",
      " (1,)\n",
      "Layer_2_Class_0.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (47, 3211264)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (3211264,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (1, 3211264)\n",
      "\n",
      "\n",
      "Layer_2_Class_1.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (962, 3211264)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (3211264,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (2, 3211264)\n",
      "\n",
      "\n",
      "Layer_2_Class_2.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (183, 3211264)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (3211264,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (3, 3211264)\n",
      "\n",
      "\n",
      "Layer_2_Class_3.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (111, 3211264)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (3211264,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (4, 3211264)\n",
      "\n",
      "\n",
      "Std between the Mean of all Classes individually for that Layer: \n",
      " (3211264,)\n",
      "Appending the Mean of the previoius Std for each Layer: \n",
      " (2,)\n",
      "Layer_4_Class_0.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (47, 1605632)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (1605632,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (1, 1605632)\n",
      "\n",
      "\n",
      "Layer_4_Class_1.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (962, 1605632)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (1605632,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (2, 1605632)\n",
      "\n",
      "\n",
      "Layer_4_Class_2.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (183, 1605632)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (1605632,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (3, 1605632)\n",
      "\n",
      "\n",
      "Layer_4_Class_3.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (111, 1605632)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (1605632,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (4, 1605632)\n",
      "\n",
      "\n",
      "Std between the Mean of all Classes individually for that Layer: \n",
      " (1605632,)\n",
      "Appending the Mean of the previoius Std for each Layer: \n",
      " (3,)\n",
      "Layer_5_Class_0.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (47, 1605632)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (1605632,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (1, 1605632)\n",
      "\n",
      "\n",
      "Layer_5_Class_1.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (962, 1605632)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (1605632,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (2, 1605632)\n",
      "\n",
      "\n",
      "Layer_5_Class_2.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (183, 1605632)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (1605632,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (3, 1605632)\n",
      "\n",
      "\n",
      "Layer_5_Class_3.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (111, 1605632)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (1605632,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (4, 1605632)\n",
      "\n",
      "\n",
      "Std between the Mean of all Classes individually for that Layer: \n",
      " (1605632,)\n",
      "Appending the Mean of the previoius Std for each Layer: \n",
      " (4,)\n",
      "Layer_7_Class_0.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (47, 802816)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (802816,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (1, 802816)\n",
      "\n",
      "\n",
      "Layer_7_Class_1.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (962, 802816)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (802816,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (2, 802816)\n",
      "\n",
      "\n",
      "Layer_7_Class_2.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (183, 802816)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (802816,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (3, 802816)\n",
      "\n",
      "\n",
      "Layer_7_Class_3.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (111, 802816)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (802816,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (4, 802816)\n",
      "\n",
      "\n",
      "Std between the Mean of all Classes individually for that Layer: \n",
      " (802816,)\n",
      "Appending the Mean of the previoius Std for each Layer: \n",
      " (5,)\n",
      "Layer_8_Class_0.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (47, 802816)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (802816,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (1, 802816)\n",
      "\n",
      "\n",
      "Layer_8_Class_1.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (962, 802816)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (802816,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (2, 802816)\n",
      "\n",
      "\n",
      "Layer_8_Class_2.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (183, 802816)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (802816,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (3, 802816)\n",
      "\n",
      "\n",
      "Layer_8_Class_3.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (111, 802816)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (802816,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (4, 802816)\n",
      "\n",
      "\n",
      "Std between the Mean of all Classes individually for that Layer: \n",
      " (802816,)\n",
      "Appending the Mean of the previoius Std for each Layer: \n",
      " (6,)\n",
      "Layer_9_Class_0.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (47, 802816)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (802816,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (1, 802816)\n",
      "\n",
      "\n",
      "Layer_9_Class_1.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (962, 802816)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (802816,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (2, 802816)\n",
      "\n",
      "\n",
      "Layer_9_Class_2.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (183, 802816)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (802816,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (3, 802816)\n",
      "\n",
      "\n",
      "Layer_9_Class_3.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (111, 802816)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (802816,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (4, 802816)\n",
      "\n",
      "\n",
      "Std between the Mean of all Classes individually for that Layer: \n",
      " (802816,)\n",
      "Appending the Mean of the previoius Std for each Layer: \n",
      " (7,)\n",
      "Layer_11_Class_0.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (47, 401408)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (401408,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (1, 401408)\n",
      "\n",
      "\n",
      "Layer_11_Class_1.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (962, 401408)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (401408,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (2, 401408)\n",
      "\n",
      "\n",
      "Layer_11_Class_2.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (183, 401408)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (401408,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (3, 401408)\n",
      "\n",
      "\n",
      "Layer_11_Class_3.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (111, 401408)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (401408,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (4, 401408)\n",
      "\n",
      "\n",
      "Std between the Mean of all Classes individually for that Layer: \n",
      " (401408,)\n",
      "Appending the Mean of the previoius Std for each Layer: \n",
      " (8,)\n",
      "Layer_12_Class_0.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (47, 401408)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (401408,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (1, 401408)\n",
      "\n",
      "\n",
      "Layer_12_Class_1.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (962, 401408)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (401408,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (2, 401408)\n",
      "\n",
      "\n",
      "Layer_12_Class_2.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (183, 401408)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (401408,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (3, 401408)\n",
      "\n",
      "\n",
      "Layer_12_Class_3.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (111, 401408)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (401408,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (4, 401408)\n",
      "\n",
      "\n",
      "Std between the Mean of all Classes individually for that Layer: \n",
      " (401408,)\n",
      "Appending the Mean of the previoius Std for each Layer: \n",
      " (9,)\n",
      "Layer_13_Class_0.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (47, 401408)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (401408,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (1, 401408)\n",
      "\n",
      "\n",
      "Layer_13_Class_1.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (962, 401408)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (401408,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (2, 401408)\n",
      "\n",
      "\n",
      "Layer_13_Class_2.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (183, 401408)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (401408,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (3, 401408)\n",
      "\n",
      "\n",
      "Layer_13_Class_3.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (111, 401408)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (401408,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (4, 401408)\n",
      "\n",
      "\n",
      "Std between the Mean of all Classes individually for that Layer: \n",
      " (401408,)\n",
      "Appending the Mean of the previoius Std for each Layer: \n",
      " (10,)\n",
      "Layer_15_Class_0.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (47, 100352)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (100352,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (1, 100352)\n",
      "\n",
      "\n",
      "Layer_15_Class_1.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (962, 100352)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (100352,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (2, 100352)\n",
      "\n",
      "\n",
      "Layer_15_Class_2.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (183, 100352)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (100352,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (3, 100352)\n",
      "\n",
      "\n",
      "Layer_15_Class_3.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (111, 100352)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (100352,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (4, 100352)\n",
      "\n",
      "\n",
      "Std between the Mean of all Classes individually for that Layer: \n",
      " (100352,)\n",
      "Appending the Mean of the previoius Std for each Layer: \n",
      " (11,)\n",
      "Layer_16_Class_0.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (47, 100352)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (100352,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (1, 100352)\n",
      "\n",
      "\n",
      "Layer_16_Class_1.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (962, 100352)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (100352,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (2, 100352)\n",
      "\n",
      "\n",
      "Layer_16_Class_2.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (183, 100352)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (100352,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (3, 100352)\n",
      "\n",
      "\n",
      "Layer_16_Class_3.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (111, 100352)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (100352,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (4, 100352)\n",
      "\n",
      "\n",
      "Std between the Mean of all Classes individually for that Layer: \n",
      " (100352,)\n",
      "Appending the Mean of the previoius Std for each Layer: \n",
      " (12,)\n",
      "Layer_17_Class_0.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (47, 100352)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (100352,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (1, 100352)\n",
      "\n",
      "\n",
      "Layer_17_Class_1.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (962, 100352)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (100352,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (2, 100352)\n",
      "\n",
      "\n",
      "Layer_17_Class_2.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (183, 100352)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (100352,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (3, 100352)\n",
      "\n",
      "\n",
      "Layer_17_Class_3.npy \n",
      "\n",
      "Class Features of All Images in that Class: \n",
      " (111, 100352)\n",
      "Mean of the Features of All Images in that Class: \n",
      " (100352,)\n",
      "Appending Classes Mean for that Layer: \n",
      " (4, 100352)\n",
      "\n",
      "\n",
      "Std between the Mean of all Classes individually for that Layer: \n",
      " (100352,)\n",
      "Appending the Mean of the previoius Std for each Layer: \n",
      " (13,)\n"
     ]
    }
   ],
   "source": [
    "Mean_Layer = []\n",
    "\n",
    "for layer_id in [1, 2, 4, 5, 7, 8, 9, 11, 12, 13, 15, 16, 17]:\n",
    "    \n",
    "    MeanVetClass = []\n",
    "    layer_output_Vet = [] \n",
    "    \n",
    "    for class_index in [0, 1, 2, 3]:\n",
    "        LoadStrName = 'Layer_' + str(layer_id) +   '_'+ 'Class_' + str(class_index) + '.npy'\n",
    "        print(LoadStrName, '\\n')\n",
    "        TempLoad = np.load(LoadStrName)\n",
    "        print(\"Class Features of All Images in that Class: \\n\",TempLoad.shape)\n",
    "        layer_output_Vet_Mean = TempLoad.mean(axis=0)\n",
    "        print(\"Mean of the Features of All Images in that Class: \\n\", layer_output_Vet_Mean.shape)\n",
    "        layer_output_Vet.append(layer_output_Vet_Mean) # Uses lots of memory!\n",
    "        print(\"Appending Classes Mean for that Layer: \\n\", np.array(layer_output_Vet).shape)\n",
    "        del TempLoad\n",
    "        print('\\n')\n",
    "        \n",
    "    layer_output_Vet = np.array(layer_output_Vet)\n",
    "    Std_Layer = layer_output_Vet.std(axis=0)       \n",
    "    print(\"Std between the Mean of all Classes individually for that Layer: \\n\", Std_Layer.shape)\n",
    "    Mean_Layer.append(Std_Layer.mean())\n",
    "    print(\"Appending the Mean of the previoius Std for each Layer: \\n\",  np.array(Mean_Layer).shape )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show statistical results for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean_Layer_For_Plot = np.load(outfile)\n",
    "layers_array = ('1','2','3','4','5','6','7', '8','9','10','11','12','13')\n",
    "layers_x = list(range(0,len(Mean_Layer_For_Plot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BarPlotter(layers_x, Mean_Layer_For_Plot):\n",
    "    \n",
    "    layers_array = ('1','2','3','4','5','6','7', '8','9','10','11','12','13')\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.bar(layers_x, Mean_Layer_For_Plot, align='center', alpha=0.6)\n",
    "    plt.plot(layers_x,Mean_Layer_For_Plot,'b')\n",
    "    plt.xticks(layers_x, layers_array)\n",
    "    plt.ylabel('Standard Deviation')\n",
    "    plt.xlabel('Convolutional Layer')\n",
    "    plt.rc('grid', linestyle=\"dotted\", color='black')\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0,0.28])\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile18 = 'Mean_Layer_' + str(18) + '.npy'\n",
    "outfile14 = 'Mean_Layer_' + str(14) + '.npy'\n",
    "outfile10 = 'Mean_Layer_' + str(10) + '.npy'\n",
    "Mean_Layer_For_Plot18 = np.load(outfile18)\n",
    "Mean_Layer_For_Plot14 = np.load(outfile14)\n",
    "Mean_Layer_For_Plot10 = np.load(outfile10)\n",
    "layers_x = list(range(0,len(Mean_Layer_For_Plot18)))\n",
    "\n",
    "BarPlotter(layers_x, Mean_Layer_For_Plot18)\n",
    "BarPlotter(layers_x, Mean_Layer_For_Plot14)\n",
    "BarPlotter(layers_x, Mean_Layer_For_Plot10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
